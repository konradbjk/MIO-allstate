{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_feats = train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for feat in cat_feats:\n",
    "    train[feat + '_id'] = preprocessing.LabelEncoder().fit_transform(train[feat].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_feats = [feat for feat in train.columns if 'cont' in feat]\n",
    "id_feats  = [feat for feat in train.columns if '_id' in feat]\n",
    "\n",
    "X = train[num_feats + id_feats].values\n",
    "y = train['loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    max_depth = 12,\n",
    "    learning_rate = 0.2,\n",
    "    n_estimators = 3,\n",
    "    silent = 0,\n",
    "    objective = 'reg:linear',\n",
    "    nthread = -1,\n",
    "    # gamma = 5290.,\n",
    "    # min_child_weight = 4.2922,\n",
    "    subsample = 0.6,\n",
    "    colsample_bytree = 0.6,\n",
    "    seed = 2017\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:2445.53\tvalidation_1-mae:2457.49\n",
      "[1]\tvalidation_0-mae:1998.29\tvalidation_1-mae:2018.68\n",
      "[2]\tvalidation_0-mae:1684.17\tvalidation_1-mae:1718.06\n",
      "[3]\tvalidation_0-mae:1472.59\tvalidation_1-mae:1523.3\n",
      "[4]\tvalidation_0-mae:1340.96\tvalidation_1-mae:1407.47\n",
      "[5]\tvalidation_0-mae:1250.06\tvalidation_1-mae:1333.96\n",
      "[6]\tvalidation_0-mae:1194.43\tvalidation_1-mae:1292.69\n",
      "[7]\tvalidation_0-mae:1153.1\tvalidation_1-mae:1262.62\n",
      "[8]\tvalidation_0-mae:1124.19\tvalidation_1-mae:1246.91\n",
      "[9]\tvalidation_0-mae:1101.67\tvalidation_1-mae:1237.68\n",
      "[10]\tvalidation_0-mae:1083.74\tvalidation_1-mae:1232.83\n",
      "[11]\tvalidation_0-mae:1069.49\tvalidation_1-mae:1230.73\n",
      "[12]\tvalidation_0-mae:1057.9\tvalidation_1-mae:1229.59\n",
      "[13]\tvalidation_0-mae:1047.65\tvalidation_1-mae:1229.64\n",
      "[14]\tvalidation_0-mae:1039.6\tvalidation_1-mae:1229.57\n",
      "[15]\tvalidation_0-mae:1030.16\tvalidation_1-mae:1229.64\n",
      "[16]\tvalidation_0-mae:1021.05\tvalidation_1-mae:1230.18\n",
      "[17]\tvalidation_0-mae:1014.16\tvalidation_1-mae:1230\n",
      "[18]\tvalidation_0-mae:1008.46\tvalidation_1-mae:1230.26\n",
      "[19]\tvalidation_0-mae:1001.72\tvalidation_1-mae:1229.76\n",
      "[20]\tvalidation_0-mae:996.909\tvalidation_1-mae:1229.37\n",
      "[21]\tvalidation_0-mae:990.443\tvalidation_1-mae:1228.47\n",
      "[22]\tvalidation_0-mae:986.208\tvalidation_1-mae:1228.24\n",
      "[23]\tvalidation_0-mae:978.511\tvalidation_1-mae:1228.27\n",
      "[24]\tvalidation_0-mae:972.939\tvalidation_1-mae:1227.83\n",
      "[25]\tvalidation_0-mae:966.732\tvalidation_1-mae:1227.55\n",
      "[26]\tvalidation_0-mae:963.264\tvalidation_1-mae:1227.8\n",
      "[27]\tvalidation_0-mae:959.6\tvalidation_1-mae:1228.22\n",
      "[28]\tvalidation_0-mae:956.251\tvalidation_1-mae:1228.27\n",
      "[29]\tvalidation_0-mae:953.863\tvalidation_1-mae:1228.15\n",
      "[30]\tvalidation_0-mae:948.484\tvalidation_1-mae:1228.05\n",
      "[31]\tvalidation_0-mae:946.373\tvalidation_1-mae:1228.17\n",
      "[32]\tvalidation_0-mae:943.045\tvalidation_1-mae:1228.28\n",
      "[33]\tvalidation_0-mae:936.673\tvalidation_1-mae:1227.98\n",
      "[34]\tvalidation_0-mae:933.022\tvalidation_1-mae:1228.27\n",
      "[35]\tvalidation_0-mae:929.324\tvalidation_1-mae:1228.06\n",
      "[36]\tvalidation_0-mae:927.391\tvalidation_1-mae:1228.42\n",
      "[37]\tvalidation_0-mae:925.057\tvalidation_1-mae:1228.6\n",
      "[38]\tvalidation_0-mae:918.689\tvalidation_1-mae:1228.78\n",
      "[39]\tvalidation_0-mae:915.674\tvalidation_1-mae:1228.7\n",
      "[40]\tvalidation_0-mae:912.052\tvalidation_1-mae:1228.84\n",
      "[41]\tvalidation_0-mae:908.528\tvalidation_1-mae:1229.06\n",
      "[42]\tvalidation_0-mae:903.446\tvalidation_1-mae:1229.48\n",
      "[43]\tvalidation_0-mae:900.489\tvalidation_1-mae:1229.66\n",
      "[44]\tvalidation_0-mae:898.407\tvalidation_1-mae:1230.4\n",
      "[45]\tvalidation_0-mae:895.89\tvalidation_1-mae:1230.44\n",
      "[46]\tvalidation_0-mae:892.222\tvalidation_1-mae:1230.67\n",
      "[47]\tvalidation_0-mae:890.335\tvalidation_1-mae:1230.87\n",
      "[48]\tvalidation_0-mae:884.586\tvalidation_1-mae:1231.26\n",
      "[49]\tvalidation_0-mae:881.624\tvalidation_1-mae:1231.57\n",
      "Fold1, score=1231.56424092\n",
      "[0]\tvalidation_0-mae:2457.09\tvalidation_1-mae:2430.94\n",
      "[1]\tvalidation_0-mae:2006.38\tvalidation_1-mae:1991.43\n",
      "[2]\tvalidation_0-mae:1692.26\tvalidation_1-mae:1694.31\n",
      "[3]\tvalidation_0-mae:1480.21\tvalidation_1-mae:1500.01\n",
      "[4]\tvalidation_0-mae:1346.86\tvalidation_1-mae:1383.45\n",
      "[5]\tvalidation_0-mae:1252.36\tvalidation_1-mae:1311.56\n",
      "[6]\tvalidation_0-mae:1195.06\tvalidation_1-mae:1271.83\n",
      "[7]\tvalidation_0-mae:1152.13\tvalidation_1-mae:1244.49\n",
      "[8]\tvalidation_0-mae:1123.95\tvalidation_1-mae:1231.58\n",
      "[9]\tvalidation_0-mae:1102.4\tvalidation_1-mae:1224.38\n",
      "[10]\tvalidation_0-mae:1084.8\tvalidation_1-mae:1220.13\n",
      "[11]\tvalidation_0-mae:1069.4\tvalidation_1-mae:1218.89\n",
      "[12]\tvalidation_0-mae:1059.3\tvalidation_1-mae:1219.02\n",
      "[13]\tvalidation_0-mae:1047.87\tvalidation_1-mae:1219.21\n",
      "[14]\tvalidation_0-mae:1037.23\tvalidation_1-mae:1220.16\n",
      "[15]\tvalidation_0-mae:1030.51\tvalidation_1-mae:1221.3\n",
      "[16]\tvalidation_0-mae:1023.35\tvalidation_1-mae:1222.31\n",
      "[17]\tvalidation_0-mae:1015.39\tvalidation_1-mae:1222.78\n",
      "[18]\tvalidation_0-mae:1007.29\tvalidation_1-mae:1223.18\n",
      "[19]\tvalidation_0-mae:1003.3\tvalidation_1-mae:1223.91\n",
      "[20]\tvalidation_0-mae:997.389\tvalidation_1-mae:1224.14\n",
      "[21]\tvalidation_0-mae:992.968\tvalidation_1-mae:1224.01\n",
      "[22]\tvalidation_0-mae:988.994\tvalidation_1-mae:1224.28\n",
      "[23]\tvalidation_0-mae:982.889\tvalidation_1-mae:1224.33\n",
      "[24]\tvalidation_0-mae:977.598\tvalidation_1-mae:1224.43\n",
      "[25]\tvalidation_0-mae:971.495\tvalidation_1-mae:1224.47\n",
      "[26]\tvalidation_0-mae:968.817\tvalidation_1-mae:1224.28\n",
      "[27]\tvalidation_0-mae:961.673\tvalidation_1-mae:1224.14\n",
      "[28]\tvalidation_0-mae:958.299\tvalidation_1-mae:1224.14\n",
      "[29]\tvalidation_0-mae:955.602\tvalidation_1-mae:1224.43\n",
      "[30]\tvalidation_0-mae:952.869\tvalidation_1-mae:1224.7\n",
      "[31]\tvalidation_0-mae:948.617\tvalidation_1-mae:1224.45\n",
      "[32]\tvalidation_0-mae:943.803\tvalidation_1-mae:1224.84\n",
      "[33]\tvalidation_0-mae:940.876\tvalidation_1-mae:1224.79\n",
      "[34]\tvalidation_0-mae:936.151\tvalidation_1-mae:1224.83\n",
      "[35]\tvalidation_0-mae:931.64\tvalidation_1-mae:1225.02\n",
      "[36]\tvalidation_0-mae:927.628\tvalidation_1-mae:1224.86\n",
      "[37]\tvalidation_0-mae:923.777\tvalidation_1-mae:1224.74\n",
      "[38]\tvalidation_0-mae:916.95\tvalidation_1-mae:1224.71\n",
      "[39]\tvalidation_0-mae:912.553\tvalidation_1-mae:1224.94\n",
      "[40]\tvalidation_0-mae:906.3\tvalidation_1-mae:1225.03\n",
      "[41]\tvalidation_0-mae:904.003\tvalidation_1-mae:1225.34\n",
      "[42]\tvalidation_0-mae:898.335\tvalidation_1-mae:1225.94\n",
      "[43]\tvalidation_0-mae:892.023\tvalidation_1-mae:1226.09\n",
      "[44]\tvalidation_0-mae:886.263\tvalidation_1-mae:1226.35\n",
      "[45]\tvalidation_0-mae:882.974\tvalidation_1-mae:1226.44\n",
      "[46]\tvalidation_0-mae:879.66\tvalidation_1-mae:1227.02\n",
      "[47]\tvalidation_0-mae:875.769\tvalidation_1-mae:1227.43\n",
      "[48]\tvalidation_0-mae:872.184\tvalidation_1-mae:1227.93\n",
      "[49]\tvalidation_0-mae:868.619\tvalidation_1-mae:1228.17\n",
      "Fold2, score=1228.15492959\n",
      "[0]\tvalidation_0-mae:2437.9\tvalidation_1-mae:2461.4\n",
      "[1]\tvalidation_0-mae:1992.77\tvalidation_1-mae:2022.64\n",
      "[2]\tvalidation_0-mae:1682.87\tvalidation_1-mae:1724.49\n",
      "[3]\tvalidation_0-mae:1473.15\tvalidation_1-mae:1529.86\n",
      "[4]\tvalidation_0-mae:1332.6\tvalidation_1-mae:1405.76\n",
      "[5]\tvalidation_0-mae:1246.3\tvalidation_1-mae:1334.19\n",
      "[6]\tvalidation_0-mae:1182.22\tvalidation_1-mae:1288.36\n",
      "[7]\tvalidation_0-mae:1143.02\tvalidation_1-mae:1263.52\n",
      "[8]\tvalidation_0-mae:1115.82\tvalidation_1-mae:1247.44\n",
      "[9]\tvalidation_0-mae:1095.02\tvalidation_1-mae:1237.82\n",
      "[10]\tvalidation_0-mae:1078.17\tvalidation_1-mae:1232.17\n",
      "[11]\tvalidation_0-mae:1065.29\tvalidation_1-mae:1229.68\n",
      "[12]\tvalidation_0-mae:1058.12\tvalidation_1-mae:1229.02\n",
      "[13]\tvalidation_0-mae:1046.78\tvalidation_1-mae:1228.83\n",
      "[14]\tvalidation_0-mae:1038.61\tvalidation_1-mae:1228.93\n",
      "[15]\tvalidation_0-mae:1030.88\tvalidation_1-mae:1229.21\n",
      "[16]\tvalidation_0-mae:1025.45\tvalidation_1-mae:1229.65\n",
      "[17]\tvalidation_0-mae:1020.53\tvalidation_1-mae:1230.36\n",
      "[18]\tvalidation_0-mae:1017.07\tvalidation_1-mae:1230.44\n",
      "[19]\tvalidation_0-mae:1011.19\tvalidation_1-mae:1230.41\n",
      "[20]\tvalidation_0-mae:1006.59\tvalidation_1-mae:1230.31\n",
      "[21]\tvalidation_0-mae:1001.65\tvalidation_1-mae:1230.85\n",
      "[22]\tvalidation_0-mae:997.42\tvalidation_1-mae:1230.78\n",
      "[23]\tvalidation_0-mae:991.297\tvalidation_1-mae:1231.27\n",
      "[24]\tvalidation_0-mae:985.162\tvalidation_1-mae:1231.84\n",
      "[25]\tvalidation_0-mae:978.089\tvalidation_1-mae:1231.72\n",
      "[26]\tvalidation_0-mae:971.076\tvalidation_1-mae:1231.25\n",
      "[27]\tvalidation_0-mae:963.541\tvalidation_1-mae:1231.37\n",
      "[28]\tvalidation_0-mae:956.799\tvalidation_1-mae:1231.92\n",
      "[29]\tvalidation_0-mae:952.351\tvalidation_1-mae:1231.58\n",
      "[30]\tvalidation_0-mae:946.891\tvalidation_1-mae:1231.74\n",
      "[31]\tvalidation_0-mae:940.86\tvalidation_1-mae:1231.69\n",
      "[32]\tvalidation_0-mae:936.766\tvalidation_1-mae:1231.28\n",
      "[33]\tvalidation_0-mae:932.907\tvalidation_1-mae:1231.41\n",
      "[34]\tvalidation_0-mae:928.951\tvalidation_1-mae:1231.6\n",
      "[35]\tvalidation_0-mae:924.309\tvalidation_1-mae:1231.82\n",
      "[36]\tvalidation_0-mae:921.335\tvalidation_1-mae:1231.83\n",
      "[37]\tvalidation_0-mae:917.546\tvalidation_1-mae:1231.85\n",
      "[38]\tvalidation_0-mae:914.635\tvalidation_1-mae:1231.88\n",
      "[39]\tvalidation_0-mae:906.439\tvalidation_1-mae:1233.09\n",
      "[40]\tvalidation_0-mae:901.554\tvalidation_1-mae:1233.47\n",
      "[41]\tvalidation_0-mae:898.062\tvalidation_1-mae:1233.51\n",
      "[42]\tvalidation_0-mae:894.125\tvalidation_1-mae:1233.73\n",
      "[43]\tvalidation_0-mae:890.053\tvalidation_1-mae:1233.81\n",
      "[44]\tvalidation_0-mae:889.052\tvalidation_1-mae:1233.88\n",
      "[45]\tvalidation_0-mae:883.508\tvalidation_1-mae:1234.07\n",
      "[46]\tvalidation_0-mae:882.705\tvalidation_1-mae:1234.08\n",
      "[47]\tvalidation_0-mae:878.872\tvalidation_1-mae:1234.8\n",
      "[48]\tvalidation_0-mae:875.048\tvalidation_1-mae:1235.21\n",
      "[49]\tvalidation_0-mae:870.917\tvalidation_1-mae:1235.06\n",
      "Fold3, score=1235.02582876\n"
     ]
    }
   ],
   "source": [
    "nfolds = 3\n",
    "folds = KFold(len(y), n_folds=nfolds, shuffle = True, random_state = 2017)\n",
    "\n",
    "\n",
    "for num_iter, (train_index, test_index) in enumerate(folds):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "       eval_metric='mae',\n",
    "       eval_set=[(X[train_index], y[train_index]), (X[test_index], y[test_index])],\n",
    "       verbose=True)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred[y_pred<0] = 0\n",
    "    \n",
    "    score = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Fold{0}, score={1}\".format(num_iter+1, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task\n",
    "\n",
    "One cell above there's a model wich use y like a target variable.\n",
    "Modeify the code in order to use transformed targert variable by logarithm...\n",
    "\n",
    "\n",
    "some TIPS:\n",
    "1. y_log_train = np.log(y_train)\n",
    "2. model.fit(X_train, y_log_train, ...\n",
    "3. y_log_pred = model.predict(X_test)\n",
    "4. y_pred = np.exp(y_log_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
